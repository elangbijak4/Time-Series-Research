{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQK/7kBBPn+dM6ZX9/hzKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elangbijak4/Time-Series-Research/blob/main/Modifikasi2_TXMIXER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penambahan Layer LSTM untuk menangkap pola jangka panjang. Penambahan ini dilakukan pada Modifikasi1 TSMIXER."
      ],
      "metadata": {
        "id": "69PdOEdZXCTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def res_block_with_lstm(inputs, norm_type, activation, dropout, ff_dim, lstm_units):\n",
        "    norm = (\n",
        "        layers.LayerNormalization\n",
        "        if norm_type == 'L'\n",
        "        else layers.BatchNormalization\n",
        "    )\n",
        "\n",
        "    # Temporal Linear with Attention\n",
        "    x = norm(axis=[-2, -1])(inputs)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.MultiHeadAttention(num_heads=4, key_dim=x.shape[-1])(x, x)\n",
        "    x = layers.Dense(x.shape[-1], activation=activation)(x)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "\n",
        "    # Adding LSTM layer\n",
        "    x = layers.LSTM(lstm_units, return_sequences=True)(x)\n",
        "\n",
        "    # Project LSTM output to match input dimension\n",
        "    x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
        "\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feature Linear\n",
        "    x = norm(axis=[-2, -1])(res)\n",
        "    x = layers.Dense(ff_dim, activation=activation)(\n",
        "        x\n",
        "    )  # [Batch, Input Length, FF_Dim]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    return x + res\n",
        "\n",
        "# Build enhanced model with LSTM\n",
        "def build_enhanced_model_with_lstm(input_shape, pred_len, norm_type, activation, n_block, dropout, ff_dim, lstm_units, target_slice):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = inputs  # [Batch, Input Length, Channel]\n",
        "    for _ in range(n_block):\n",
        "        x = res_block_with_lstm(x, norm_type, activation, dropout, ff_dim, lstm_units)\n",
        "\n",
        "    if target_slice:\n",
        "        x = x[:, :, target_slice]\n",
        "\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.Dense(pred_len)(x)  # [Batch, Channel, Output Length]\n",
        "    outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel]\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "5HpIlKbjWuzq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}