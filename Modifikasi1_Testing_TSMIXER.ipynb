{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3Ii8K5IxNd1VQaXGLFQ7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elangbijak4/Time-Series-Research/blob/main/Modifikasi1_Testing_TSMIXER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perubahan dari TSMIXER, adalah penambahan mekanisme attention dan lapisan dropout menjadi spatialdroput1D. Pertama untuk mempertajam penyerapan pola, kedua untuk mengurangi mekanisme drop neuron yang berlebihan."
      ],
      "metadata": {
        "id": "cLbTd5QqeK3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TKqTmAyBd6Zf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def res_block(inputs, norm_type, activation, dropout, ff_dim):\n",
        "    \"\"\"Residual block of Enhanced TSMixer.\"\"\"\n",
        "    norm = (\n",
        "        layers.LayerNormalization\n",
        "        if norm_type == 'L'\n",
        "        else layers.BatchNormalization\n",
        "    )\n",
        "\n",
        "    # Temporal Linear with Attention\n",
        "    x = norm(axis=[-2, -1])(inputs)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.MultiHeadAttention(num_heads=4, key_dim=x.shape[-1])(x, x)\n",
        "    x = layers.Dense(x.shape[-1], activation=activation)(x)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feature Linear\n",
        "    x = norm(axis=[-2, -1])(res)\n",
        "    x = layers.Dense(ff_dim, activation=activation)(\n",
        "        x\n",
        "    )  # [Batch, Input Length, FF_Dim]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_enhanced_model(input_shape, pred_len, norm_type, activation, n_block, dropout, ff_dim, target_slice):\n",
        "    \"\"\"Build Enhanced TSMixer model.\"\"\"\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = inputs  # [Batch, Input Length, Channel]\n",
        "    for _ in range(n_block):\n",
        "        x = res_block(x, norm_type, activation, dropout, ff_dim)\n",
        "\n",
        "    if target_slice:\n",
        "        x = x[:, :, target_slice]\n",
        "\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.Dense(pred_len)(x)  # [Batch, Channel, Output Length]\n",
        "    outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel])\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demonstrasi penggunaan model yang dimodifikasi"
      ],
      "metadata": {
        "id": "VE5DpyrsfWnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Res block as defined before\n",
        "def res_block(inputs, norm_type, activation, dropout, ff_dim):\n",
        "    norm = (\n",
        "        layers.LayerNormalization\n",
        "        if norm_type == 'L'\n",
        "        else layers.BatchNormalization\n",
        "    )\n",
        "\n",
        "    # Temporal Linear with Attention\n",
        "    x = norm(axis=[-2, -1])(inputs)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.MultiHeadAttention(num_heads=4, key_dim=x.shape[-1])(x, x)\n",
        "    x = layers.Dense(x.shape[-1], activation=activation)(x)\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feature Linear\n",
        "    x = norm(axis=[-2, -1])(res)\n",
        "    x = layers.Dense(ff_dim, activation=activation)(\n",
        "        x\n",
        "    )  # [Batch, Input Length, FF_Dim]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n",
        "    x = layers.SpatialDropout1D(dropout)(x)\n",
        "    return x + res\n",
        "\n",
        "# Build enhanced model\n",
        "def build_enhanced_model(input_shape, pred_len, norm_type, activation, n_block, dropout, ff_dim, target_slice):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = inputs  # [Batch, Input Length, Channel]\n",
        "    for _ in range(n_block):\n",
        "        x = res_block(x, norm_type, activation, dropout, ff_dim)\n",
        "\n",
        "    if target_slice:\n",
        "        x = x[:, :, target_slice]\n",
        "\n",
        "    x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n",
        "    x = layers.Dense(pred_len)(x)  # [Batch, Channel, Output Length]\n",
        "    outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel]\n",
        "\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Data preparation\n",
        "batch_size = 64\n",
        "input_length = 30\n",
        "num_features = 10\n",
        "pred_length = 5\n",
        "\n",
        "# Generate dummy data\n",
        "x_train = np.random.rand(batch_size, input_length, num_features)\n",
        "y_train = np.random.rand(batch_size, pred_length, num_features)\n",
        "\n",
        "# Define model parameters\n",
        "input_shape = (input_length, num_features)\n",
        "norm_type = 'L'\n",
        "activation = 'relu'\n",
        "n_block = 4\n",
        "dropout = 0.1\n",
        "ff_dim = 64\n",
        "target_slice = None\n",
        "\n",
        "# Build model\n",
        "model = build_enhanced_model(input_shape, pred_length, norm_type, activation, n_block, dropout, ff_dim, target_slice)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=batch_size)\n",
        "\n",
        "# Generate new data for inference\n",
        "x_new = np.random.rand(batch_size, input_length, num_features)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_new)\n",
        "\n",
        "# Print shapes\n",
        "print(f\"Input shape: {x_new.shape}\")\n",
        "print(f\"Predicted output shape: {y_pred.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_xQhyfQfSkV",
        "outputId": "a5d02e6c-8932-4cca-b6ef-5cea7f788f47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 9s 9s/step - loss: 3.1950\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5864\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2545\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.9724\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.7330\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.5469\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.5023\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.2797\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.0967\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.0485\n",
            "2/2 [==============================] - 1s 15ms/step\n",
            "Input shape: (64, 30, 10)\n",
            "Predicted output shape: (64, 5, 10)\n"
          ]
        }
      ]
    }
  ]
}